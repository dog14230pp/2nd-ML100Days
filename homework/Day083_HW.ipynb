{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day083_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NYFqiWNilhV",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 試比較有 BN 在 Batch_size = 2, 16, 32, 128, 256 下的差異\n",
        "2. 請嘗試將 BN 放在 Activation 之前，並比較訓練結果\n",
        "3. 請於 BN 放在 Input Layer 後，並比較結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT6_9nnxilhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import itertools\n",
        "from keras.layers import BatchNormalization\n",
        "# Disable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-tpXGgoilhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5d6b0dce-83fa-4cd4-a98c-7a3d0c683c07"
      },
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Qu_QCeilha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtStjI_Nilhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zQ1CR0_ilhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Code Here\n",
        "建立你的神經網路\n",
        "\"\"\"\n",
        "def build_mlp(input_shape, output_dim = 10, neurons = [512, 256, 128, 64, 32, 16, 8]):\n",
        "    model = keras.models.Sequential()\n",
        "    for i, units in enumerate(neurons):\n",
        "      if i == 0:\n",
        "          model.add(keras.layers.Dense(units = units, activation = 'relu', name = \"hidden_layer\" + str(i), input_shape = input_shape))\n",
        "          model.add(BatchNormalization())\n",
        "      else:\n",
        "          model.add(keras.layers.Dense(units = units, activation = 'relu', name = \"hidden_layer\" + str(i)))\n",
        "          model.add(BatchNormalization())\n",
        "    model.add(keras.layers.Dense(units = output_dim, activation = 'softmax', name = \"output\"))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2rektP6ilhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = [16, 32, 128, 256]\n",
        "MOMENTUM = 0.95"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "22J3U60Iilhh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9c55ca8-9407-4090-d1e0-1b76cb984d94"
      },
      "source": [
        "results = {}\n",
        "\"\"\"\n",
        "使用迴圈建立不同的帶不同 L1/L2 的模型並訓練\n",
        "\"\"\"\n",
        "for batch_size in BATCH_SIZE:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    print(\"Experiment with batch_size = %d\" % (batch_size))\n",
        "    model = build_mlp(input_shape=x_train.shape[1:])\n",
        "    model.summary()\n",
        "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "    model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=batch_size, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "    # Collect results\n",
        "    train_loss = model.history.history[\"loss\"]\n",
        "    valid_loss = model.history.history[\"val_loss\"]\n",
        "    train_acc = model.history.history[\"acc\"]\n",
        "    valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "    exp_name_tag = \"exp-batch_size-%s\" % str(batch_size)\n",
        "    results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with batch_size = 16\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 41s 829us/step - loss: 2.1479 - acc: 0.2280 - val_loss: 1.9583 - val_acc: 0.3058\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 40s 808us/step - loss: 1.9537 - acc: 0.3040 - val_loss: 1.8309 - val_acc: 0.3598\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 41s 817us/step - loss: 1.8755 - acc: 0.3381 - val_loss: 1.7832 - val_acc: 0.3662\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 42s 833us/step - loss: 1.8218 - acc: 0.3560 - val_loss: 1.7318 - val_acc: 0.3822\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 40s 807us/step - loss: 1.7819 - acc: 0.3683 - val_loss: 1.6877 - val_acc: 0.4119\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 40s 806us/step - loss: 1.7527 - acc: 0.3799 - val_loss: 1.6822 - val_acc: 0.4127\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 40s 802us/step - loss: 1.7322 - acc: 0.3868 - val_loss: 1.6401 - val_acc: 0.4222\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 40s 794us/step - loss: 1.7117 - acc: 0.3941 - val_loss: 1.6257 - val_acc: 0.4271\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 39s 788us/step - loss: 1.6869 - acc: 0.4024 - val_loss: 1.6194 - val_acc: 0.4267\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 40s 802us/step - loss: 1.6735 - acc: 0.4060 - val_loss: 1.5899 - val_acc: 0.4429\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 40s 803us/step - loss: 1.6535 - acc: 0.4172 - val_loss: 1.5789 - val_acc: 0.4422\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 40s 802us/step - loss: 1.6393 - acc: 0.4187 - val_loss: 1.5694 - val_acc: 0.4479\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 40s 798us/step - loss: 1.6271 - acc: 0.4226 - val_loss: 1.5709 - val_acc: 0.4522\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 40s 796us/step - loss: 1.6145 - acc: 0.4298 - val_loss: 1.5432 - val_acc: 0.4572\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 39s 790us/step - loss: 1.6022 - acc: 0.4342 - val_loss: 1.5875 - val_acc: 0.4479\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 39s 790us/step - loss: 1.5897 - acc: 0.4381 - val_loss: 1.5408 - val_acc: 0.4631\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 40s 796us/step - loss: 1.5894 - acc: 0.4418 - val_loss: 1.5409 - val_acc: 0.4587\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 40s 800us/step - loss: 1.5780 - acc: 0.4412 - val_loss: 1.5330 - val_acc: 0.4576\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 40s 804us/step - loss: 1.5649 - acc: 0.4485 - val_loss: 1.5368 - val_acc: 0.4597\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 40s 799us/step - loss: 1.5562 - acc: 0.4523 - val_loss: 1.4998 - val_acc: 0.4773\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 41s 813us/step - loss: 1.5406 - acc: 0.4561 - val_loss: 1.5107 - val_acc: 0.4672\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 40s 799us/step - loss: 1.5399 - acc: 0.4577 - val_loss: 1.5200 - val_acc: 0.4659\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 40s 794us/step - loss: 1.5244 - acc: 0.4637 - val_loss: 1.5067 - val_acc: 0.4661\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 40s 793us/step - loss: 1.5191 - acc: 0.4658 - val_loss: 1.5176 - val_acc: 0.4658\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 40s 796us/step - loss: 1.5084 - acc: 0.4683 - val_loss: 1.4860 - val_acc: 0.4799\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 40s 793us/step - loss: 1.5012 - acc: 0.4708 - val_loss: 1.4697 - val_acc: 0.4845\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 40s 806us/step - loss: 1.4969 - acc: 0.4712 - val_loss: 1.4625 - val_acc: 0.4880\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 40s 797us/step - loss: 1.4784 - acc: 0.4763 - val_loss: 1.5135 - val_acc: 0.4657\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 40s 803us/step - loss: 1.4739 - acc: 0.4788 - val_loss: 1.4412 - val_acc: 0.4897\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 40s 800us/step - loss: 1.4659 - acc: 0.4819 - val_loss: 1.4493 - val_acc: 0.4968\n",
            "Experiment with batch_size = 32\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 2.1712 - acc: 0.2309 - val_loss: 1.9971 - val_acc: 0.2800\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 20s 403us/step - loss: 1.9551 - acc: 0.3049 - val_loss: 1.9099 - val_acc: 0.3274\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 20s 402us/step - loss: 1.8649 - acc: 0.3425 - val_loss: 1.8159 - val_acc: 0.3643\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 20s 403us/step - loss: 1.8013 - acc: 0.3663 - val_loss: 1.7489 - val_acc: 0.3866\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 20s 408us/step - loss: 1.7458 - acc: 0.3860 - val_loss: 1.7056 - val_acc: 0.4080\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.7085 - acc: 0.4000 - val_loss: 1.6870 - val_acc: 0.4114\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.6752 - acc: 0.4090 - val_loss: 1.6508 - val_acc: 0.4245\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.6530 - acc: 0.4178 - val_loss: 1.6267 - val_acc: 0.4322\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 21s 415us/step - loss: 1.6201 - acc: 0.4299 - val_loss: 1.6153 - val_acc: 0.4293\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 20s 406us/step - loss: 1.5980 - acc: 0.4380 - val_loss: 1.5852 - val_acc: 0.4460\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.5791 - acc: 0.4432 - val_loss: 1.5724 - val_acc: 0.4479\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.5450 - acc: 0.4563 - val_loss: 1.6075 - val_acc: 0.4268\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 20s 401us/step - loss: 1.5297 - acc: 0.4620 - val_loss: 1.5414 - val_acc: 0.4530\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 20s 406us/step - loss: 1.5088 - acc: 0.4696 - val_loss: 1.5294 - val_acc: 0.4638\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 20s 405us/step - loss: 1.4932 - acc: 0.4735 - val_loss: 1.5767 - val_acc: 0.4393\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 21s 412us/step - loss: 1.4823 - acc: 0.4765 - val_loss: 1.5313 - val_acc: 0.4629\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 21s 411us/step - loss: 1.4589 - acc: 0.4868 - val_loss: 1.5043 - val_acc: 0.4706\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 20s 400us/step - loss: 1.4431 - acc: 0.4936 - val_loss: 1.4998 - val_acc: 0.4727\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 20s 399us/step - loss: 1.4228 - acc: 0.4993 - val_loss: 1.4937 - val_acc: 0.4671\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 20s 406us/step - loss: 1.4136 - acc: 0.5011 - val_loss: 1.4729 - val_acc: 0.4771\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 20s 404us/step - loss: 1.3962 - acc: 0.5084 - val_loss: 1.4715 - val_acc: 0.4780\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 20s 402us/step - loss: 1.3846 - acc: 0.5125 - val_loss: 1.4867 - val_acc: 0.4728\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 20s 408us/step - loss: 1.3765 - acc: 0.5164 - val_loss: 1.5247 - val_acc: 0.4563\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 21s 417us/step - loss: 1.3686 - acc: 0.5182 - val_loss: 1.4567 - val_acc: 0.4847\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 20s 408us/step - loss: 1.3460 - acc: 0.5256 - val_loss: 1.4492 - val_acc: 0.4874\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 20s 407us/step - loss: 1.3390 - acc: 0.5282 - val_loss: 1.4812 - val_acc: 0.4821\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 20s 407us/step - loss: 1.3236 - acc: 0.5352 - val_loss: 1.4757 - val_acc: 0.4764\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 20s 406us/step - loss: 1.3226 - acc: 0.5357 - val_loss: 1.4584 - val_acc: 0.4871\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 20s 401us/step - loss: 1.3090 - acc: 0.5406 - val_loss: 1.4697 - val_acc: 0.4883\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 20s 403us/step - loss: 1.2919 - acc: 0.5485 - val_loss: 1.4456 - val_acc: 0.4926\n",
            "Experiment with batch_size = 128\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 2.3140 - acc: 0.1887 - val_loss: 2.1456 - val_acc: 0.2289\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 2.0332 - acc: 0.2692 - val_loss: 2.0216 - val_acc: 0.2706\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 1.9401 - acc: 0.3064 - val_loss: 1.9481 - val_acc: 0.3055\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.8760 - acc: 0.3341 - val_loss: 1.8871 - val_acc: 0.3327\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 1.8312 - acc: 0.3495 - val_loss: 1.8511 - val_acc: 0.3450\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 1.7889 - acc: 0.3687 - val_loss: 1.8189 - val_acc: 0.3557\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.7495 - acc: 0.3806 - val_loss: 1.8100 - val_acc: 0.3627\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.7204 - acc: 0.3925 - val_loss: 1.7766 - val_acc: 0.3742\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 1.6893 - acc: 0.4030 - val_loss: 1.7598 - val_acc: 0.3795\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.6681 - acc: 0.4098 - val_loss: 1.7443 - val_acc: 0.3829\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 1.6399 - acc: 0.4193 - val_loss: 1.7242 - val_acc: 0.3915\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.6148 - acc: 0.4300 - val_loss: 1.7159 - val_acc: 0.3949\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.5959 - acc: 0.4353 - val_loss: 1.7056 - val_acc: 0.3979\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.5716 - acc: 0.4416 - val_loss: 1.6902 - val_acc: 0.4005\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.5536 - acc: 0.4475 - val_loss: 1.6976 - val_acc: 0.4013\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.5312 - acc: 0.4579 - val_loss: 1.6909 - val_acc: 0.4020\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 6s 116us/step - loss: 1.5160 - acc: 0.4607 - val_loss: 1.6713 - val_acc: 0.4123\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 6s 115us/step - loss: 1.4980 - acc: 0.4687 - val_loss: 1.6680 - val_acc: 0.4153\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.4823 - acc: 0.4721 - val_loss: 1.6640 - val_acc: 0.4104\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.4658 - acc: 0.4817 - val_loss: 1.6525 - val_acc: 0.4203\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 1.4448 - acc: 0.4846 - val_loss: 1.6531 - val_acc: 0.4178\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.4297 - acc: 0.4921 - val_loss: 1.6357 - val_acc: 0.4246\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.4149 - acc: 0.4968 - val_loss: 1.6441 - val_acc: 0.4233\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.3987 - acc: 0.5039 - val_loss: 1.6358 - val_acc: 0.4247\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.3839 - acc: 0.5081 - val_loss: 1.6238 - val_acc: 0.4277\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.3640 - acc: 0.5172 - val_loss: 1.6693 - val_acc: 0.4225\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.3520 - acc: 0.5205 - val_loss: 1.6361 - val_acc: 0.4249\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.3368 - acc: 0.5251 - val_loss: 1.6263 - val_acc: 0.4322\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.3217 - acc: 0.5323 - val_loss: 1.6438 - val_acc: 0.4296\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.3079 - acc: 0.5363 - val_loss: 1.6223 - val_acc: 0.4390\n",
            "Experiment with batch_size = 256\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 5s 98us/step - loss: 2.4977 - acc: 0.1523 - val_loss: 2.4075 - val_acc: 0.1910\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 4s 71us/step - loss: 2.2263 - acc: 0.2126 - val_loss: 2.2394 - val_acc: 0.2105\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 3s 70us/step - loss: 2.1308 - acc: 0.2378 - val_loss: 2.1355 - val_acc: 0.2411\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 3s 68us/step - loss: 2.0654 - acc: 0.2634 - val_loss: 2.0810 - val_acc: 0.2548\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 2.0145 - acc: 0.2846 - val_loss: 2.0481 - val_acc: 0.2763\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.9758 - acc: 0.3042 - val_loss: 2.0196 - val_acc: 0.2883\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.9359 - acc: 0.3264 - val_loss: 1.9899 - val_acc: 0.3017\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 4s 71us/step - loss: 1.9030 - acc: 0.3387 - val_loss: 1.9580 - val_acc: 0.3158\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 4s 70us/step - loss: 1.8719 - acc: 0.3546 - val_loss: 1.9378 - val_acc: 0.3329\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.8416 - acc: 0.3693 - val_loss: 1.9212 - val_acc: 0.3409\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.8134 - acc: 0.3828 - val_loss: 1.8905 - val_acc: 0.3483\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.7878 - acc: 0.3903 - val_loss: 1.8746 - val_acc: 0.3620\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 3s 70us/step - loss: 1.7632 - acc: 0.3994 - val_loss: 1.8564 - val_acc: 0.3615\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 4s 71us/step - loss: 1.7370 - acc: 0.4114 - val_loss: 1.8374 - val_acc: 0.3655\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.7135 - acc: 0.4176 - val_loss: 1.8214 - val_acc: 0.3737\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.6927 - acc: 0.4250 - val_loss: 1.8148 - val_acc: 0.3752\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.6715 - acc: 0.4339 - val_loss: 1.8050 - val_acc: 0.3777\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.6495 - acc: 0.4406 - val_loss: 1.7959 - val_acc: 0.3805\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 3s 68us/step - loss: 1.6294 - acc: 0.4462 - val_loss: 1.7784 - val_acc: 0.3832\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 3s 68us/step - loss: 1.6105 - acc: 0.4528 - val_loss: 1.7681 - val_acc: 0.3855\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.5901 - acc: 0.4596 - val_loss: 1.7597 - val_acc: 0.3861\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.5718 - acc: 0.4650 - val_loss: 1.7499 - val_acc: 0.3904\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.5528 - acc: 0.4717 - val_loss: 1.7497 - val_acc: 0.3884\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.5373 - acc: 0.4758 - val_loss: 1.7435 - val_acc: 0.3939\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.5190 - acc: 0.4817 - val_loss: 1.7374 - val_acc: 0.3941\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.5017 - acc: 0.4888 - val_loss: 1.7297 - val_acc: 0.3972\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.4863 - acc: 0.4948 - val_loss: 1.7258 - val_acc: 0.4003\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.4711 - acc: 0.4970 - val_loss: 1.7161 - val_acc: 0.4014\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.4555 - acc: 0.5038 - val_loss: 1.7198 - val_acc: 0.4008\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 1.4433 - acc: 0.5068 - val_loss: 1.7203 - val_acc: 0.4008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs32p08milhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b5babd8f-bb59-4f69-f1d1-28514f52c5d8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGXa//HPlU5CGkkgIcXQSQih\nJCBIF1SKDUHRtT+7tnVX3eLis/u46j5b3Gf9ra67Kmuvi4vYEUVcqQJKTeiEnkYqaaRn7t8fZ0DE\nNJJJJjO53q9XXkxmTs5ch3nxzc197nMdMcaglFLKvXg4uwCllFKOp+GulFJuSMNdKaXckIa7Ukq5\nIQ13pZRyQxruSinlhjTclVLKDWm4K7cnIkdFZIaz61CqM2m4K6WUG9JwV92WiNwhIgdFpFhEPhKR\nvvbnRUSeFJF8ESkTkZ0ikmR/bbaI7BGRchHJFpFfOvcolGqchrvqlkTkYuBPwHVAFHAMeNv+8qXA\nZGAwEGzfpsj+2kvAXcaYQCAJ+LITy1aq1bycXYBSTnIj8LIxZhuAiPw3cFJE4oE6IBAYCnxjjNl7\n1s/VAYkikmaMOQmc7NSqlWolHbmr7qov1mgdAGNMBdboPNoY8yXwD+AZIF9EnheRIPum84DZwDER\nWSMi4zu5bqVaRcNddVc5wAWnvxGRACAMyAYwxjxtjEkBErGmZx60P7/ZGHMV0Bv4AFjSyXUr1Soa\n7qq78BYRv9NfwGLgdhEZKSK+wB+Br40xR0VkjIhcKCLewCmgGrCJiI+I3CgiwcaYOqAMsDntiJRq\nhoa76i6WA1VnfU0FHgbeBXKBAcD19m2DgBew5tOPYU3X/MX+2s3AUREpA+7GmrtXqssRvVmHUkq5\nHx25K6WUG9JwV0opN6ThrpRSbkjDXSml3JDTrlANDw838fHxznp7pZRySVu3bi00xkS0tJ3Twj0+\nPp4tW7Y46+2VUsolicixlrfSaRmllHJLGu5KKeWGNNyVUsoNactfpZRD1dXVkZWVRXV1tbNLcWl+\nfn7ExMTg7e3dpp/XcFdKOVRWVhaBgYHEx8cjIs4uxyUZYygqKiIrK4t+/fq1aR86LaOUcqjq6mrC\nwsI02NtBRAgLC2vX/3403JVSDqfB3n7t/Tt0uXDff6KcPy3fS2VtvbNLUUqpLsvlwj2zuJJ/rj3M\n7pwyZ5eilOqCSkpKePbZZ9v0s7Nnz6akpKTV2z/66KM88cQTbXqvjuZy4Z4cGwxAWmbrPwClVPfR\nXLjX1zf/P/7ly5cTEhLSEWV1OpcL996BfkQF+5GeVersUpRSXdBDDz3EoUOHGDlyJA8++CCrV69m\n0qRJXHnllSQmJgJw9dVXk5KSwrBhw3j++efP/Gx8fDyFhYUcPXqUhIQE7rjjDoYNG8all15KVVVV\ns++7Y8cOxo0bR3JyMnPnzuXkyZMAPP300yQmJpKcnMz111s3+1qzZg0jR45k5MiRjBo1ivLycof/\nPbjkUsjkmGDSs3TkrlRX99jHu9nj4CnUxL5BPHLFsCZff/zxx9m1axc7duwAYPXq1Wzbto1du3ad\nWVb48ssv06tXL6qqqhgzZgzz5s0jLCzsO/vJyMhg8eLFvPDCC1x33XW8++673HTTTU2+7y233MLf\n//53pkyZwm9/+1see+wxnnrqKR5//HGOHDmCr6/vmSmfJ554gmeeeYYJEyZQUVGBn59fe/9avsfl\nRu4AyTEhHC2qpLSyztmlKKVcwNixY7+zXvzpp59mxIgRjBs3jszMTDIyMr73M/369WPkyJEApKSk\ncPTo0Sb3X1paSklJCVOmTAHg1ltvZe3atQAkJydz44038uabb+LlZY2nJ0yYwM9//nOefvppSkpK\nzjzvSC47cgfYmV3KxEHhTq5GKdWU5kbYnSkgIODM49WrV/PFF1+wceNG/P39mTp1aqPryX19fc88\n9vT0bHFapimffPIJa9eu5eOPP+YPf/gDO3fu5KGHHmLOnDksX76cCRMmsGLFCoYOHdqm/TfFNUfu\n0dYJjzSdmlFKnSMwMLDZOezS0lJCQ0Px9/dn3759bNq0qd3vGRwcTGhoKOvWrQPgjTfeYMqUKdhs\nNjIzM5k2bRp//vOfKS0tpaKigkOHDjF8+HAWLlzImDFj2LdvX7trOJdLjtyD/b2JD/PXeXel1PeE\nhYUxYcIEkpKSmDVrFnPmzPnO6zNnzmTRokUkJCQwZMgQxo0b55D3fe2117j77ruprKykf//+vPLK\nKzQ0NHDTTTdRWlqKMYb77ruPkJAQHn74YVatWoWHhwfDhg1j1qxZDqnhbGKMcfhOWyM1NdW052Yd\n9y3ezpajxWz47+kOrEop1V579+4lISHB2WW4hcb+LkVkqzEmtaWfdclpGbDm3XNKqykor3F2KUop\n1eW4cLhb8+46NaOUUt/nsuGeFB2Eh0CaXsyklFLf47Lh7u/jxaDegTpyV0qpRrhsuIM1774zyzoL\nrZRS6luuHe6xIRSdqiW7pG0XFyillLtqMdxFJFZEVonIHhHZLSL3N7PtGBGpF5H5ji2zcSPsV6pq\nEzGlVHv07NkTgJycHObPbzy+pk6dSmPLt5t63tlaM3KvB35hjEkExgH3ikjiuRuJiCfwZ+Bzx5Z4\njpzt8O4dUFvJkMhAvD1Fr1RVSjlE3759Wbp0qbPLcIgWw90Yk2uM2WZ/XA7sBaIb2fSnwLtAvkMr\nPFdVCexcAge/wNfLk4SoINIzdeSulLI89NBDPPPMM2e+P31DjYqKCqZPn87o0aMZPnw4H3744fd+\n9ujRoyQlJQFQVVXF9ddfT0JCAnPnzm1Vb5nFixczfPhwkpKSWLhwIQANDQ3cdtttJCUlMXz4cJ58\n8kmg8VbAjnRe7QdEJB4YBXx9zvPRwFxgGjDGQbU1Ln4S+IfB7vch8UqSY4L5cHsONpvBw0Pv26hU\nl/LpQ3Bip2P3GTkcZj3e5MsLFizggQce4N577wVgyZIlrFixAj8/P95//32CgoIoLCxk3LhxXHnl\nlU3eq/S5557D39+fvXv3kp6ezujRo5stKycnh4ULF7J161ZCQ0O59NJL+eCDD4iNjSU7O5tdu3YB\nnGn721grYEdq9QlVEemJNTJ/wBhzboPmp4CFxhhbC/u4U0S2iMiWgoKC868WwNMLEq6AAyugrork\nmBDKa+o5UnSqbftTSrmVUaNGkZ+fT05ODmlpaYSGhhIbG4sxhl//+tckJyczY8YMsrOzycvLa3I/\na9euPdO/PTk5meTk5Gbfd/PmzUydOpWIiAi8vLy48cYbWbt2Lf379+fw4cP89Kc/5bPPPiMoKOjM\nPs9tBexIrdqjiHhjBftbxpj3GtkkFXjb/hswHJgtIvXGmA/O3sgY8zzwPFi9ZdpcdeLVsPVVyFjJ\niJhpgHWl6oCInm3epVKqAzQzwu5I1157LUuXLuXEiRMsWLAAgLfeeouCggK2bt2Kt7c38fHxjbb6\ndbTQ0FDS0tJYsWIFixYtYsmSJbz88suNtgJ2ZMi3ZrWMAC8Be40xf21sG2NMP2NMvDEmHlgK/Pjc\nYHeos6ZmBkQE0MPbkzSdd1dK2S1YsIC3336bpUuXcu211wJWq9/evXvj7e3NqlWrOHbsWLP7mDx5\nMv/6178A2LVrF+np6c1uP3bsWNasWUNhYSENDQ0sXryYKVOmUFhYiM1mY968efz+979n27ZtTbYC\ndqTW/JqYANwM7BSRHfbnfg3EARhjFjm0otY4PTWT/g5ethqSooP0SlWl1BnDhg2jvLyc6OhooqKi\nALjxxhu54oorGD58OKmpqS3eHOOee+7h9ttvJyEhgYSEBFJSUprdPioqiscff5xp06ZhjGHOnDlc\nddVVpKWlcfvtt2OzWbPWf/rTn5psBexILtvyl0Or4I2r4bo3+N/DA3lz0zF2P3YZXp4ufV2WUi5P\nW/46Trds+XtmambPByTHBFNTb+NAnmP/W6OUUq7KdcP99NTM/s8YGWnd61CnZpRSyuK64Q7Wqpm6\nU8QVf0WQn5e2/1Wqi9Bmfu3X3r9D1w53+9SM7PmQ5JgQHbkr1QX4+flRVFSkAd8OxhiKiorw8/Nr\n8z5c8gbZZ5y1amb0qPt4dn0R1XUN+Hl7OrsypbqtmJgYsrKyaPOFigqwfknGxMS0+eddO9zhzAVN\n0zzTedoWxt7cMkbFhTq7KqW6LW9vb/r16+fsMro9156WgTNTM0OL/wNo+1+llAJ3CHf71Izf4ZVE\nB6Dtf5VSCncId4DEq5G6U/yg134duSulFO4S7vapmRlmI4cKKqioqXd2RUop5VTuEe72qZkBJevx\nMbXsytbRu1Kqe3OPcAdIvBqv+kqmeuzQ9e5KqW7PfcLdPjUz32+LXqmqlOr23Cfc7VMzk8wW9mU2\nfXcVpZTqDtwn3AESr8bPVDOw9GtOnqp1djVKKeU07hXu8ZOo8+3FHM9NpOtJVaVUN+Ze4e7phRk6\nh+ke29h99ISzq1FKKadxr3AHfJLnESA1mIP/cXYpSinlNG4X7sRPosIzmIEFK51diVJKOY37hbun\nF9mR05lo20xe0UlnV6OUUk7hfuEOSNI1BEgNuVuXObsUpZRyCrcM97jRl1JkAvHd/5GzS1FKKadw\ny3D38/XlG9+L6Fe8FuqqnF2OUkp1OrcMd4Ds6Jn4mWpMhp5YVUp1P24b7gGDp1JkAqna/KazS1FK\nqU7ntuE+PC6M1+ovw//ICsjc7OxylFKqU7ltuA+JDOR1uZwKr1BY+VswxtklKaVUp3HbcPf29GDk\ngGiebpgHxzdAxufOLkkppTqN24Y7wEOzhvJazRSKfGLgi8fA1uDskpRSqlO0GO4iEisiq0Rkj4js\nFpH7G9nmRhFJF5GdIrJBREZ0TLnnZ2hkEDeMG8Ajp66B/N2QvsTZJSmlVKdozci9HviFMSYRGAfc\nKyKJ52xzBJhijBkO/C/wvGPLbLufzRjMRt+JHPQahFn1e6irdnZJSinV4VoMd2NMrjFmm/1xObAX\niD5nmw3GmNONXDYBMY4utK2C/b355cwEHq68DinNgs0vOrskpZTqcOc15y4i8cAo4OtmNvsh8GkT\nP3+niGwRkS0FBQXn89btcl1qLOVR49koIzHrnoAqvYG2Usq9tTrcRaQn8C7wgDGmrIltpmGF+8LG\nXjfGPG+MSTXGpEZERLSl3jbx9BAevWIYv6++Dqk6CV/9rdPeWymlnKFV4S4i3ljB/pYx5r0mtkkG\nXgSuMsYUOa5Ex0iN78XgkRP4yDYB26ZnoSzH2SUppVSHac1qGQFeAvYaY/7axDZxwHvAzcaYA44t\n0XEemjWUZ1iArb4eVj/u7HKUUqrDtGbkPgG4GbhYRHbYv2aLyN0icrd9m98CYcCz9te3dFTB7dEn\nyI+50yfyRv10zPY3oaDL/h5SSql2EeOky/JTU1PNli2d/zugpr6BBU8u461Td9Fj6Aw8rtfGYkop\n1yEiW40xqS1t59ZXqDbG18uT+68Yz6K6OXjs+1ibiiml3FK3C3eAaUN7c3DArRSaYGo/+x9tKqaU\ncjvdMtwBFl6Zwt9t8/DJ3qRNxZRSbqfbhnt8eAA9x/+QI7Y+VC1/WJuKKaXcSrcNd4AfTx/K8z43\n0aNkP7a0t51djlJKOUy3DvcAXy8unP1fpNn6U7Xid1Dd6IW3Sinlcrp1uANcNSqapWH34FtdQN1r\nV2vfGaWUW+j24S4i/OC667mv4WeQm4bttSuhstjZZSmlVLt0+3AHSIgK4orrfsQdtT+jIW8P5rXL\n4VShs8tSSqk203C3mzU8inGX3cDtNb+kvuAgvDoHyvOcXZZSSrWJhvtZ7prcn9jU2dxc/SB1xcfg\n1dnaPVIp5ZI03M8iIvzuqiS8B0zmxuqF1JedgFdmQ0mms0tTSqnzouF+Dm9PD565cTQnw0ZzW92v\naThVZAV88RFnl6aUUq2m4d6IID9vXr5tDPu8BnOXxyPYasqtOfiiQ84uTSmlWkXDvQmxvfx54ZZU\n1lVE86D/HzD1NfDKLCjY7+zSlFKqRRruzRgVF8qTC0bybk4If+rzBAasKZqcHc4uTSmlmqXh3oLZ\nw6P41cwhPL/Xh1cGPwOePvDCxfDpQr2aVSnVZWm4t8I9UwawIDWW322oZdmEdyDlVvj6n/D30bD1\nNe0oqZTqcjTcW0FE+P3cJC4aEMbPPj7OxoT/gbvWQPhg+Pg+aySvd3RSSnUhGu6t5O3pwXM3pXBB\nWAC3v/oNX5ZGwu2fwjUvQkUevDQD3r9Hr2pVSnUJGu7nIbiHN2/fOY5BvQO54/WtLN2WDcnXwk+2\nwMSfwa6l8PcU+OppqK91drlKqW5Mw/08hff0ZfGd4xjXvxe/fCeNRWsOYXwCYMaj8ONNED8BVj4M\nz10EGV/o/VmVUk6h4d4GPX29ePm2MVyeHMXjn+7jD5/sxWYzEDYAfvBv+ME7YGzw1jx49XI4+pWz\nS1ZKdTMa7m3k6+XJ09eP4raL4nlx/RF+vmQHtfU268XBl8KPN8Ks/4OiDKsB2WtXwvGvnVu0Uqrb\n0HBvBw8P4ZErEnnwsiF8sCOHH72+hVM19daLXr5w4V1wfxpc9kfI3wMvXwpvXANZW5xbuFLK7Wm4\nt5OIcO+0gTx+zXDWZxTwgxe/pvjUWSdTvXvA+HutkL/kd5CzHV6cDm9dZz1WSqkOoOHuINePjWPR\nTSnsyy1j/qINZJ2s/O4GPgEw4X54IB2m/xYyv4bnp8LiH0BuulNqVkq5Lw13B7p0WCRv/PBCCspr\nmPfcBvafKP/+Rr6BMOkX8MBOmPYbOLoe/jkJltwKhRmdX7RSyi21GO4iEisiq0Rkj4jsFpH7G9lG\nRORpETkoIukiMrpjyu36xvbrxTt3j8cYmL9oA5+k5za+oV8QTPmVNZKf/CvIWAnPXAgf/RRKszu3\naKWU22nNyL0e+IUxJhEYB9wrIonnbDMLGGT/uhN4zqFVupihkUG8e89F9A8P4N5/beOBt7dTWlnX\n+MY9QuDi31hz8mPvgB2L4elR8Pn/QGVx5xaulHIbLYa7MSbXGLPN/rgc2AtEn7PZVcDrxrIJCBGR\nKIdX60Jie/mz9J6LeGDGID5Oz+Wyp9ayPqOw6R/oGQGz/gw/3QpJ82DDP+BvI2DtX6D2VOcVrpRy\nC+c15y4i8cAo4NwF29HA2TcazeL7vwC6HW9PDx6YMZj3f3wRAb6e3PTS1zz60W6qapvpIhl6Acx9\nDu7ZAPGT4Mvfw99GwjcvaEsDpVSrtTrcRaQn8C7wgDGmrC1vJiJ3isgWEdlSUFDQll24pOSYED65\nbxK3XRTPqxuOcvnf15Ge1UIv+D6JcMO/4IcrIXwQLP8l/CMV0peAzdY5hSulXFarwl1EvLGC/S1j\nzHuNbJINxJ71fYz9ue8wxjxvjEk1xqRGRES0pV6X5eftyaNXDuPNH15IZW0D1zy7gb99kUFdQwtB\nHTsWbvsEbnzXOgn73h3w4sVwfFPnFK6UckmtWS0jwEvAXmPMX5vY7CPgFvuqmXFAqTGmiWUi3dvE\nQeF89sBkLk+O4skvDjD/uQ0cKqho/odEYNAMuHMtzP2n1Vb45cvgnduh5HjnFK6UciliWuhaKCIT\ngXXATuD0MPPXQByAMWaR/RfAP4CZQCVwuzGm2WvsU1NTzZYt3fsy/E/Sc/nNBzuprmvgN7MTuGnc\nBVh/lS2oPWW1Ff7qb1aDsot+YrUc9g3s+KKVUk4lIluNMaktbtdSuHcUDXdLflk1Dy5NZ82BAqYP\n7c2f5ycT3tO3dT9cmgVfPAY7l0DPPtaVryN+AB56bZpS7qq14a4p4GS9g/x49fYxPHpFIusOFjLz\nqXWsOdDKk83BMTDvBfjRfyAkDj68F16Yqi2GlVIa7l2BiHDbhH589JMJhAX4cOvL3/C7j/dQXdfK\nG2/HpFqraua9BKeKrBbDS26B/L0dW7hSqsvSaZkuprqugcc/3cerG44yNDKQp28YxeA+5zGXXldl\nXQC1/q9QVwlRIyB5ASTNh8A+HVe4UqpT6Jy7i1u1L58Hl6ZRXl3Pr2cncMv4Vp5sPe1UIexcCulv\nW62FxQP6T4MR18PQOVaXSqWUy9FwdwMF5TU8uDSN1fsLmDYkgr9cO6L1J1u/s6MDkP5v6wKo0uPg\nHQAJV0DyddB/Knh4Orp0pVQH0XB3E8YYXttwlD9+uo8gPy/+cu0Ipg3p3bad2WyQuQnS3obdH0BN\nqbXKJmk+DJ0NsReCp7djD0Ap5VAa7m5m34ky7l+8g/155Vwxoi//PWsofUN6tH2HddWQscIazR9Y\nAbY68A2GgdNh8EwYdAn493LcASilHELD3Q1V1zXw3OpDLFpzCA8R7p02gB9N6o+fdzunVWrK4dAq\nK+wPfA6n8q05+pixMPgy66t3onWlrFLKqTTc3VhmcSV/XL6XT3edILZXDx6ek8gliX3O74RrU2w2\nyN1uhfyBzyB3h/V8cKwV8iNvhOhuey8WpZxOw70bWJ9RyGMf7yYjv4LJgyP47eWJDOzd07FvUpYL\nGZ9bX4dWQd0pq9/8xQ9Dr36OfS+lVIs03LuJugYbb2w8xpNfHKCqtoHbJ8Rz3/RBBPp1wInRmnKr\nn82Gf4CtHsbeCZN/qXPzSnUiDfduprCihr98tp8lWzMJC/DloVlDuWZUNB4eHTBPXpYLq/8I298E\nn0CY/AsYexd4+zn+vZRS36Hh3k2lZZbwyEe72ZFZwoiYYH4zJ5Gx/TpoZJ23B754xJqyCY61pmqG\nX6uNy5TqQBru3ZjNZnhvezZPrNjPibJqLhvWh4Uzh9I/wsHz8acdXgMrH4bcNIhMhkv/17o4Sinl\ncBruiqraBl5cd5jn1hyitt7GTeMu4L7pg+gV4OP4N7PZYNe78J/fWVfB9p9qnXgdOAOC+jr+/ZTq\npjTc1Rn55dU89UUGb39znABfL3568UBuGR/f/vXxjamrhs0vwKbnoMx+p8Xew6w7SQ28xLoK1qsD\nfrko1U1ouKvvOZBXzp+W72XV/gJiQnvwq5lDuSI5yjHr489ljNVy+OBKyFhp3fPVVmedgO0/xRrR\nD7rE6kmvlGo1DXfVpPUZhfxh+V725pYxMjaE38xJYEx8By9nrCm35uYProSML6Asy3o+IgGGzISE\nK6HvKL0KVqkWaLirZjXYDO9ty+KJz/eTV1bDJYl9WDhzCAN7d8J9WI2Bgn1w8Atrpc3Rr8A0QHAc\nJF5pBX3MGF11o1QjNNxVq1TVNvDS+sMsWnOYytp6rkuN5YEZg4kM7sQ165XFsH857PnQugrWVgeB\nUVZb4oQr4YKLtC2xUnYa7uq8FJ+q5e9fZvDmpmN4egj/NaEfd08dQFBHXOnanOpSq0vlng+tkX19\nNQREWDcYSbwK4ieDp1fn1qRUF6Lhrtoks7iSJz7fz4c7cgjx9+Yn0wZy8/gL8PVywsi5psKao9/z\nodXIrO4U+IdZo/lhcyF+oo7oVbej4a7aZVd2KX/+bB/rMgqJDunBLy8bzFUjOqidQWvUVVkj+d3v\nw/5PrfvDBvS2RvNJ10DsOJ2jV92ChrtyiHUZBTz+6T5255SREBXEry4bwtQhER2zfLK1aiut3vO7\n3rNOyNZXW3P0iVdbQR8zRlfdKLel4a4cxmYzfJyewxOf7yezuIqRsSE8MGMQUwY7OeTBWmJ5wB70\nB1dCQ63V52bIbGsdffxE8G7HHauU6mI03JXD1dbbWLo1i2dWHSS7pIpRcSH8bMZgJg0Kd37Ig3Uy\ndt9ya+rmyBprRO/lZwX8wEussA8b4OwqlWoXDXfVYWrrbSzZkskzqw6SW1pNygWh/GzGYCYMDOsa\nIQ/WHP3Rr769Qrb4kPV8aD8r5AfaR/U+/s6tU6nzpOGuOlxNfQNLNmfyzKpDnCirZky8FfLjB3Sh\nkD+t+DAc/I8V9EfWQn2VNaqPHQu9+lttEIJjv/0zqC94dvIyUKVaQcNddZrqugb+vTmTZ1cfJK+s\nhrH9evGzGYMZ179X1wt5sJqbHfvKWn1zfCOUZsGpgnM2EuskbXCM9RUSC70GQJ9hEDEUfDuofbJS\nLXBYuIvIy8DlQL4xJqmR14OBN4E4wAt4whjzSktvrOHufqrrGlj8zXGeXX2IgvIaRsSGcNfk/lw2\nLBJPZy2hbK26KijNhtJMK+xLs+yPz/q+ofbb7UPjrW6XfRKhd4L1OGygXmClOpwjw30yUAG83kS4\n/xoINsYsFJEIYD8QaYypPXfbs2m4u6/qugbe2ZLJC+uOcLy4kgvC/PnRxH7MT4mlh4+LXnRks0HJ\nUevuU/l7IG+39WfRIasvDoCnD4QPsYf9UOtxxFDrF4GGvnIQh07LiEg8sKyJcP9vIBa4F4gHVgKD\njTG25vap4e7+GmyGFbtP8M+1h0nLLKFXgA83j7uAW8ZfQFhPX2eX5xh11VB44LuBn7/32172YIV+\n2CCIsId9xBDrq9cA7W2vzltnhnsg8BEwFAgEFhhjPmliP3cCdwLExcWlHDt2rMX3Vq7PGMM3R4p5\nfu1h/rMvHz9vD+anxPCjif2JDw9wdnkdo7oMCjOs7pcF+6BgPxTuh5PHAPu/OQ8viE6x+uYMvVyX\naapW6cxwnw9MAH4ODMAauY8wxpQ1t08duXdPGXnlvLjuCO9vz6bOZmPmsEjumNyf0XGhzi6tc9RW\nQlGGFfZ5u+HQl3Ai3XotYqgV9EPmWL3ttZ2CakRnhvsnwOPGmHX2778EHjLGfNPcPjXcu7f8smpe\n3XCUNzcdo6y6nlFxIfzXhH7MSorEy7ObhVrJceviq33L4NgGaw4/MMq6ynboHIifpNM36ozODPfn\ngDxjzKMi0gfYhjVyL2xunxruCuBUTT1Lt2bxyldHOFpUSd9gP269KJ7rx8QR7N8N15lXFlv9cvYt\ns9bl11WCbxAMmAZRIyFyOPRJgsBI7Z/TTTlytcxiYCoQDuQBjwDeAMaYRSLSF3gViAIEaxT/Zktv\nrOGuzmazGb7cl89L64+w8XAR/j6ezE+J4baL4ukf0U3XlNdVweHVsO8T6xaFpce/fc0/zAr502Ef\nmWStztERvtvTi5iUy9qdU8orXx3lox051NlsXDykNz+c2K9rXvnamapKrHn6vF1wYqf1Z/5eq4cO\ngIf3tytxwgZB+CDrJG3YQPBojrzKAAAQ1UlEQVTthNsnqk6h4a5cXn55NW9uOs5bm45RdKqWoZGB\n3D1lAJcnR3W/efmmNNRbfXNOh/2JXdaqnJJMzqzKAWsOP2yg9RU+yB7+AyEkXk/cuhgNd+U2qusa\n+GhHDi+sO0xGfgXRIT24c3J/rkt14YuiOlpdtdVPpygDig5C4UHrcWEGVJd8u523v7VKp0/iWVfc\nDoOeEc6rXTVLw125ndPz8s+tOcTWYyfpFeDD7RfFc8v4+O558rWtThV9uxwzfy/k77auvK08aw1E\nQAT0TrR66fROhB72paoigJx1Mle+fQ6sOf/AvlbjNe2/0yE03JVb23y0mOdWH+LLffkE+Hhyw9g4\nfjipH1HBemOONqvI//Yq27w9Vujn77M6aLaFbzAER1tBHxRt/+prf87+WM8FnDcNd9Ut7M0t459r\nDvFxei4eAnNHRXPn5AEM7K2jRoewNcDJo1B7CjBgDGfm8k8/Nnz7XF0VlOda7RfKcqxmbGX2r+91\n3sRa5hnU1zoncDrwg85+HG39r6E7n0g/h4a76lYyiyt5cd1h3t6cSW2DjelDe3Pz+HgmDQx33k29\n1XfV11jBfybwc6yv8pxvH1fkwbltqbx6WM3XevWHXv2++zg4rts1ZdNwV91SUUUNr208xr++PkZh\nRS39wgO4adwFzE+JIbiHzst3eQ31VsCfHfqlWVB8xDpBfPLIt0s/werPExxrBX2v/tAzEnqEWKP9\nHqHffewb7BYrgzTcVbdWU9/AZ7tO8PrGY2w9dpIe3p5cPaovN4+LJ7FvkLPLU21ls0HFie+GffFh\n+/dHoKa06Z8VD/ALtoI+oLfVlrn3Wf34A8I67zjaQcNdKbtd2aW8sfEYH6ZlU11nY0x8KDePj2fm\nsEh8vFx/JKfOUl9rLfWsOtn8V1mudeL47GWhAb3tQW8P/D7DrAvCPLzt+yxp/s+acus8hLHZvxrO\nemz77mvD58OYH7XpEDXclTpHaWUd72zN5I1NxzhWVElEoC83jIllfkoscWF6o+xuxxhrCihvt31J\n6F4r8Av2WT19Wss3CPxCrKWfHp7W/xCa/RJImgcpt7WpbA13pZpgsxnWZBTwxsZjrNqfjzEwtl8v\n5qfEMHt4FD19u9cJOnWO03fdOh348O3cvV+I9djP/r1vUKef0NVwV6oVckqqeH97Nu9uzeJw4Sl6\neHsyMymS+SkxjO8fpittVJej4a7UeTDGsO14Ce9uy+LjtBzKq+vpG+zHNaNjmJcSQz93vWOUcjka\n7kq1UXVdAyv35LF0axbrMgqwGUi5IJT5KTFcnhxFoJ8uqVTOo+GulAPklVXz/vZslm7N4mB+BX7e\nHswcFsm1qbE6baOcQsNdKQcyxpCWVco7WzL5yD5tEx3Sg3kpMVybEkNsL11tozqHhrtSHaS6roHP\n9+TxzpZM1h8sxBgY178X16bEMmt4JP4+utpGdRwNd6U6QU5JFe9ty2Lp1iyOFlUS4OPJnOQoFoyJ\nY3RcSPe+c5TqEBruSnUiYwybj55k6dZMlqXnUlnbwOA+PVkwJo5rRkUTGqD3NlWOoeGulJNU1NSz\nLC2HxZszScsswcfTg8uSIrl+jJ6EVe2n4a5UF7A3t4x/b87kvW1ZlFXXE9fLnwVjYpmfEkOfID9n\nl6dckIa7Ul1IdV0DK3afYPE3x9l0uBhPD2HakN5cmxrD1CER+HrpvWBV67Q23PW0vlKdwM/bk6tG\nRnPVyGiOFJ7i35szWbo1iy/25hHcw5s5yVHMHRVNSlyoTtsoh9CRu1JOUtdgY/3BQj7Yns3nu/Oo\nqmsgOqQHV4/qy9xR0QzsrfcXVd+n0zJKuZBTNfV8vucE72/PYb295UFSdBBXj4zmyhF96a3z88pO\nw10pF5VfXs2ytFw+2JFNelYpHgIXDQjnihFRXDYskhB/XVbZnWm4K+UGDuZX8OGObD7ckcPx4kq8\nPISJg8KZMzyKS4dF6n1huyENd6XciDGGXdllLEvPYVl6LtklVXh7CpMHRXD5iChmJPTRbpXdhMPC\nXUReBi4H8o0xSU1sMxV4CvAGCo0xU1p6Yw13pdrmdBOzZWk5fLIzl9zSany8PJg6OII5yVFckthH\n+9u4MUeG+2SgAni9sXAXkRBgAzDTGHNcRHobY/JbemMNd6Xaz2YzbM8sYVl6Dst35pJXVoO/jycz\nh0Uyd3Q0Fw0Ix1OXVroVh07LiEg8sKyJcP8x0NcY8z/nU6CGu1KOZbMZNh8t5oMd2SxLz6W8up4+\nQb5cNTKaa0ZHMzQyyNklKgfozHA/PR0zDAgE/maMeb2lfWq4K9Vxqusa+HJfPu9ty2L1/gLqbYaE\nqCCuGRXNVSN1aaUr68xw/weQCkwHegAbgTnGmAONbHsncCdAXFxcyrFjx1p8b6VU+xRV1LAsPZf3\ntmeTllmCh8CEgeFcMzpaT8S6oM4M94eAHsaYR+zfvwR8Zox5p7l96shdqc53qKCC97dl8/72bLJL\nqvDx9GDSoHBmDY/ikoQ+BPtr0Hd1ndlb5kPgHyLiBfgAFwJPOmC/SikHGxDRk19eNoSfXzKYbcdP\n8umuE3y6M5f/7MvHy0OYMDCc2cMjuSQxkl7ag96ltWa1zGJgKhAO5AGPYM2xY4xZZN/mQeB2wAa8\naIx5qqU31pG7Ul3D6aWVn+7MZfmuXDKLq/D0EMb3D2PW8EguTYwkItDX2WUqO72ISSl13owx7M4p\nY/nOXJbvzOVoUSUeAhf2C+PyEVHMSorSEb2TabgrpdrFGMO+E+Us35nLJ+m5HC48haeHcNGAMK5I\n7stlwyJ1jt4JNNyVUg5jjGFPbhnL0nNZlp5DZrHV/mDSoAgut18Vq6tuOoeGu1KqQxhjSM8qZVl6\nDp+k55JzTvuDyYMi9IbgHUjDXSnV4az2Byf5OM2ao88vr0EEkqODmTw4gsmDIxgZG4K3p4ezS3Ub\nGu5KqU5lsxl2ZJWw7kAhazMK2H78JDYDgb5ejB8QxuTBEUwZHEFsL39nl+rSNNyVUk5VWlXHxkOF\nrDlQyNoDBWSXVAEQH+bP5MERTE/ow0UDwnRUf5403JVSXYYxhiOFp1h7oIC1GYVsPFREVV0DwT28\nuSSxD7OHRzJhYDi+Xp7OLrXL03BXSnVZ1XUNrM8oZPmuXFbuyaO8up5AXy9mJPZhZlIkUwZH4Oet\nQd+Yzmw/oJRS58XP25MZiX2YkdiH2nobXx0q5NOduXy+J4/3t2fj7+PJxUN7M3t4FFOHROjNR9pA\nR+5KqS6jrsHG14eLWb4rlxW7TlB0qhZfL6u52SWJfZie0Ifwnt27FYJOyyilXFqDzfDNkWJW7D7B\nyj15ZJdUIQKj40K5JLEPlyT2YUBET2eX2ek03JVSbuP0FbIr9+Sxck8eu3PKAOgfHnAm6EfFhXaL\nWwpquCul3FZ2SRX/2WsF/cZDRdTbDGEBPkwZEsHkQRFMHBTuttM3Gu5KqW6hrLqO1fsL+GJPHusy\nCjhZWQfAsL5BTBoUweTB4aRcEOo2yyw13JVS3U6DzbA7p5R1GYWsOVDAtmMnqbcZenh7Mq5/L3vY\nRzAgIgAR15zC0XBXSnV7FTX1bDpUxNqMAtZlFHKk8BQAfYP9mGSfvpkwMNyletRruCul1Dkyiyut\noD9QyFeHCimvrkcEhkcHM3FgOJMGRZByQSg+Xl23JYKGu1JKNaO+wUZ6dinrDhSy/mAB246X0GAz\n+Pt4cmE/awpn0qBwBvbu2aWmcDTclVLqPJRX17HpcDHrMgpYn1HIYfsUTlSwH5Ptc/UTB4Y7/e5T\nGu5KKdUOWScrWZdRyDr7fH15dT0eAiNjQ870qh8RE9Lpa+s13JVSykHqG2ykZZWw5oC1Cic9qwRj\nILiHNxMHhTPFfnK2b0iPDq9Fw10ppTrIyVO1rD9o9alfc6CA/PIawJrCGRUXwqjYUEZfEMKwvsEO\n726pXSGVUqqDhAb4cMWIvlwxoi/GGPbnlbPxUBHbj5ewPfMky3eeAMDbU0iMCmJUXOiZ0I/t1aNT\nTtDqyF0ppRysoLyGHZklbD9+ku3HS0jLKqGytgGAsAAf7p4ygDsm92/TvnXkrpRSThIR6HumoRlY\nc/YZ+RVsP17CtuMn6R3U8X1vNNyVUqqDeXl6kBAVREJUED+4MK5T3rPrXoallFKqzTTclVLKDWm4\nK6WUG2ox3EXkZRHJF5FdLWw3RkTqRWS+48pTSinVFq0Zub8KzGxuAxHxBP4MfO6AmpRSSrVTi+Fu\njFkLFLew2U+Bd4F8RxSllFKqfdo95y4i0cBc4LlWbHuniGwRkS0FBQXtfWullFJNcMQJ1aeAhcYY\nW0sbGmOeN8akGmNSIyIiHPDWSimlGtOq9gMiEg8sM8YkNfLaEeB0o4RwoBK40xjzQQv7LACOnWe9\np4UDhW382a7K3Y7J3Y4H3O+Y3O14wP2OqbHjucAY0+LouN1XqBpj+p1+LCKvYv0SaDbY7T/X5qG7\niGxpTW8FV+Jux+RuxwPud0zudjzgfsfUnuNpMdxFZDEwFQgXkSzgEcAbwBizqC1vqpRSqmO1GO7G\nmBtauzNjzG3tqkYppZRDuOoVqs87u4AO4G7H5G7HA+53TO52POB+x9Tm43FaP3ellFIdx1VH7kop\npZqh4a6UUm7I5cJdRGaKyH4ROSgiDzm7HkcQkaMislNEdoiIy917sLHmciLSS0RWikiG/c9QZ9Z4\nvpo4pkdFJNv+Oe0QkdnOrPF8iEisiKwSkT0isltE7rc/75KfUzPH48qfkZ+IfCMiafZjesz+fD8R\n+dqeef8WEZ9W7c+V5tztDcoOAJcAWcBm4AZjzB6nFtZOInIUSDXGuOTFFyIyGagAXj99oZuI/B9Q\nbIx53P5LONQYs9CZdZ6PJo7pUaDCGPOEM2trCxGJAqKMMdtEJBDYClwN3IYLfk7NHM91uO5nJECA\nMaZCRLyB9cD9wM+B94wxb4vIIiDNGNNiuxdXG7mPBQ4aYw4bY2qBt4GrnFxTt9dEc7mrgNfsj1/D\n+ofnMlrZMM9lGGNyjTHb7I/Lgb1ANC76OTVzPC7LWCrs33rbvwxwMbDU/nyrPyNXC/doIPOs77Nw\n8Q/UzgCfi8hWEbnT2cU4SB9jTK798QmgjzOLcaCfiEi6fdrGJaYwzmVvJzIK+Bo3+JzOOR5w4c9I\nRDxFZAdWh92VwCGgxBhTb9+k1ZnnauHuriYaY0YDs4B77VMCbsNYc3+uM//XtOeAAcBIIBf4f84t\n5/yJSE+s9twPGGPKzn7NFT+nRo7HpT8jY0yDMWYkEIM1UzG0rftytXDPBmLP+j7G/pxLM8Zk2//M\nB97H+lBdXZ59XvT0/KjL9/o3xuTZ//HZgBdwsc/JPo/7LvCWMeY9+9Mu+zk1djyu/hmdZowpAVYB\n44EQETndTaDVmedq4b4ZGGQ/e+wDXA985OSa2kVEAuwnhBCRAOBSoNlbGrqIj4Bb7Y9vBT50Yi0O\ncToE7ebiQp+T/WTdS8BeY8xfz3rJJT+npo7HxT+jCBEJsT/ugbVwZC9WyJ++fWmrPyOXWi0DYF/a\n9BTgCbxsjPmDk0tqFxHpjzVaB6vXz79c7ZjObi4H5GE1l/sAWALEYbV2vs4Y4zInKJs4pqlY/903\nwFHgrrPmq7s0EZkIrAN2AqfvvfBrrHlql/ucmjmeG3DdzygZ64SpJ9bAe4kx5nf2jHgb6AVsB24y\nxtS0uD9XC3ellFItc7VpGaWUUq2g4a6UUm5Iw10ppdyQhrtSSrkhDXellHJDGu5KKeWGNNyVUsoN\n/X+aIk1ozHOW+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxELfGGPqEQt9Y4ypRyz0jTGmHvn/zBij5xzmX4EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwuZgPl6uM_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Code Here\n",
        "建立你的神經網路\n",
        "\"\"\"\n",
        "def build_mlp(input_shape, output_dim = 10, neurons = [512, 256, 128, 64, 32, 16, 8]):\n",
        "    model = keras.models.Sequential()\n",
        "    for i, units in enumerate(neurons):\n",
        "      if i == 0:\n",
        "          model.add(keras.layers.Dense(units = units, name = \"hidden_layer\" + str(i), input_shape = input_shape))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(keras.layers.Activation('relu'))\n",
        "      else:\n",
        "          model.add(keras.layers.Dense(units = units,  name = \"hidden_layer\" + str(i)))\n",
        "          model.add(BatchNormalization())\n",
        "          model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.Dense(units = output_dim, activation = 'softmax', name = \"output\"))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gz-O-jHu1KO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49d9a2d1-5c69-49bb-c060-c6e1d6b8778a"
      },
      "source": [
        "results = {}\n",
        "\"\"\"\n",
        "使用迴圈建立不同的帶不同 L1/L2 的模型並訓練\n",
        "\"\"\"\n",
        "for batch_size in BATCH_SIZE:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    print(\"Experiment with batch_size = %d\" % (batch_size))\n",
        "    model = build_mlp(input_shape=x_train.shape[1:])\n",
        "    model.summary()\n",
        "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "    model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=batch_size, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "    # Collect results\n",
        "    train_loss = model.history.history[\"loss\"]\n",
        "    valid_loss = model.history.history[\"val_loss\"]\n",
        "    train_acc = model.history.history[\"acc\"]\n",
        "    valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "    exp_name_tag = \"exp-batch_size-%s\" % str(batch_size)\n",
        "    results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with batch_size = 16\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 40s 804us/step - loss: 2.1480 - acc: 0.2235 - val_loss: 1.9843 - val_acc: 0.2985\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 39s 780us/step - loss: 1.9554 - acc: 0.2996 - val_loss: 1.8548 - val_acc: 0.3397\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 39s 789us/step - loss: 1.8575 - acc: 0.3348 - val_loss: 1.7604 - val_acc: 0.3761\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 39s 780us/step - loss: 1.7955 - acc: 0.3567 - val_loss: 1.6975 - val_acc: 0.3983\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 39s 785us/step - loss: 1.7430 - acc: 0.3789 - val_loss: 1.6602 - val_acc: 0.4114\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 39s 782us/step - loss: 1.7018 - acc: 0.3907 - val_loss: 1.6304 - val_acc: 0.4186\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 39s 778us/step - loss: 1.6749 - acc: 0.4036 - val_loss: 1.5934 - val_acc: 0.4309\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 39s 776us/step - loss: 1.6393 - acc: 0.4167 - val_loss: 1.5702 - val_acc: 0.4429\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 39s 778us/step - loss: 1.6147 - acc: 0.4275 - val_loss: 1.5807 - val_acc: 0.4374\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 39s 780us/step - loss: 1.5851 - acc: 0.4378 - val_loss: 1.5299 - val_acc: 0.4539\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 39s 783us/step - loss: 1.5694 - acc: 0.4448 - val_loss: 1.5216 - val_acc: 0.4574\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 38s 770us/step - loss: 1.5408 - acc: 0.4571 - val_loss: 1.5282 - val_acc: 0.4589\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 39s 773us/step - loss: 1.5197 - acc: 0.4647 - val_loss: 1.5145 - val_acc: 0.4633\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 1.4918 - acc: 0.4737 - val_loss: 1.5052 - val_acc: 0.4662\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 37s 742us/step - loss: 1.4839 - acc: 0.4760 - val_loss: 1.4664 - val_acc: 0.4825\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 1.4575 - acc: 0.4853 - val_loss: 1.4569 - val_acc: 0.4852\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 37s 740us/step - loss: 1.4433 - acc: 0.4893 - val_loss: 1.4778 - val_acc: 0.4799\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 1.4199 - acc: 0.4984 - val_loss: 1.4709 - val_acc: 0.4813\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 1.4040 - acc: 0.5071 - val_loss: 1.4476 - val_acc: 0.4899\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 1.3835 - acc: 0.5135 - val_loss: 1.5032 - val_acc: 0.4762\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 37s 735us/step - loss: 1.3646 - acc: 0.5240 - val_loss: 1.4662 - val_acc: 0.4926\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 37s 733us/step - loss: 1.3479 - acc: 0.5262 - val_loss: 1.4367 - val_acc: 0.4961\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 1.3300 - acc: 0.5329 - val_loss: 1.4832 - val_acc: 0.4694\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 38s 759us/step - loss: 1.3232 - acc: 0.5360 - val_loss: 1.4863 - val_acc: 0.4846\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 40s 801us/step - loss: 1.3046 - acc: 0.5408 - val_loss: 1.4148 - val_acc: 0.5041\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 40s 796us/step - loss: 1.2926 - acc: 0.5452 - val_loss: 1.4456 - val_acc: 0.4934\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 38s 768us/step - loss: 1.2756 - acc: 0.5552 - val_loss: 1.3838 - val_acc: 0.5174\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 38s 762us/step - loss: 1.2604 - acc: 0.5559 - val_loss: 1.4221 - val_acc: 0.5059\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 38s 764us/step - loss: 1.2478 - acc: 0.5634 - val_loss: 1.4088 - val_acc: 0.4946\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 39s 778us/step - loss: 1.2418 - acc: 0.5655 - val_loss: 1.4279 - val_acc: 0.5008\n",
            "Experiment with batch_size = 32\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 21s 413us/step - loss: 2.2438 - acc: 0.1791 - val_loss: 2.1391 - val_acc: 0.2428\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 2.0988 - acc: 0.2685 - val_loss: 2.0509 - val_acc: 0.3123\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 2.0085 - acc: 0.3291 - val_loss: 1.9733 - val_acc: 0.3482\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 1.9297 - acc: 0.3618 - val_loss: 1.8894 - val_acc: 0.3743\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 19s 390us/step - loss: 1.8640 - acc: 0.3837 - val_loss: 1.8454 - val_acc: 0.3900\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 20s 391us/step - loss: 1.7998 - acc: 0.3996 - val_loss: 1.7855 - val_acc: 0.3970\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 1.7452 - acc: 0.4149 - val_loss: 1.7451 - val_acc: 0.4157\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 19s 390us/step - loss: 1.6881 - acc: 0.4318 - val_loss: 1.6893 - val_acc: 0.4233\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 1.6400 - acc: 0.4446 - val_loss: 1.6576 - val_acc: 0.4396\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 20s 391us/step - loss: 1.5897 - acc: 0.4618 - val_loss: 1.6224 - val_acc: 0.4429\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.5442 - acc: 0.4718 - val_loss: 1.6144 - val_acc: 0.4324\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 19s 388us/step - loss: 1.5070 - acc: 0.4845 - val_loss: 1.5785 - val_acc: 0.4511\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.4678 - acc: 0.4975 - val_loss: 1.5589 - val_acc: 0.4631\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.4302 - acc: 0.5089 - val_loss: 1.5549 - val_acc: 0.4551\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 20s 401us/step - loss: 1.4043 - acc: 0.5169 - val_loss: 1.5480 - val_acc: 0.4596\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 1.3741 - acc: 0.5221 - val_loss: 1.5652 - val_acc: 0.4611\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 19s 390us/step - loss: 1.3460 - acc: 0.5363 - val_loss: 1.5221 - val_acc: 0.4655\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.3151 - acc: 0.5478 - val_loss: 1.5463 - val_acc: 0.4624\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.2992 - acc: 0.5507 - val_loss: 1.5633 - val_acc: 0.4575\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.2756 - acc: 0.5583 - val_loss: 1.5051 - val_acc: 0.4813\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.2508 - acc: 0.5683 - val_loss: 1.5067 - val_acc: 0.4839\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.2242 - acc: 0.5770 - val_loss: 1.5049 - val_acc: 0.4760\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 20s 395us/step - loss: 1.2064 - acc: 0.5830 - val_loss: 1.5226 - val_acc: 0.4745\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 1.1893 - acc: 0.5884 - val_loss: 1.5022 - val_acc: 0.4826\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 1.1645 - acc: 0.5985 - val_loss: 1.5761 - val_acc: 0.4623\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 20s 397us/step - loss: 1.1436 - acc: 0.6041 - val_loss: 1.5389 - val_acc: 0.4775\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.1250 - acc: 0.6089 - val_loss: 1.4765 - val_acc: 0.4960\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 1.1169 - acc: 0.6119 - val_loss: 1.5253 - val_acc: 0.4754\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.0900 - acc: 0.6222 - val_loss: 1.5180 - val_acc: 0.4839\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 20s 402us/step - loss: 1.0768 - acc: 0.6271 - val_loss: 1.4883 - val_acc: 0.4955\n",
            "Experiment with batch_size = 128\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 2.3408 - acc: 0.1360 - val_loss: 2.2546 - val_acc: 0.1787\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 2.1944 - acc: 0.2118 - val_loss: 2.1708 - val_acc: 0.2346\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 2.1243 - acc: 0.2566 - val_loss: 2.1241 - val_acc: 0.2597\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 2.0739 - acc: 0.2841 - val_loss: 2.0866 - val_acc: 0.2739\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 2.0295 - acc: 0.3033 - val_loss: 2.0558 - val_acc: 0.2856\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.9912 - acc: 0.3161 - val_loss: 2.0202 - val_acc: 0.2976\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.9535 - acc: 0.3275 - val_loss: 1.9899 - val_acc: 0.3093\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.9178 - acc: 0.3424 - val_loss: 1.9672 - val_acc: 0.3208\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.8863 - acc: 0.3516 - val_loss: 1.9417 - val_acc: 0.3317\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.8519 - acc: 0.3632 - val_loss: 1.9190 - val_acc: 0.3355\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.8232 - acc: 0.3732 - val_loss: 1.9084 - val_acc: 0.3391\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.7905 - acc: 0.3852 - val_loss: 1.8879 - val_acc: 0.3459\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 5s 110us/step - loss: 1.7616 - acc: 0.3941 - val_loss: 1.8653 - val_acc: 0.3498\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.7316 - acc: 0.4027 - val_loss: 1.8510 - val_acc: 0.3596\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 1.7027 - acc: 0.4117 - val_loss: 1.8354 - val_acc: 0.3624\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.6760 - acc: 0.4227 - val_loss: 1.8075 - val_acc: 0.3713\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.6499 - acc: 0.4322 - val_loss: 1.8004 - val_acc: 0.3700\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.6228 - acc: 0.4403 - val_loss: 1.8040 - val_acc: 0.3729\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.5960 - acc: 0.4485 - val_loss: 1.7781 - val_acc: 0.3789\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.5712 - acc: 0.4566 - val_loss: 1.7691 - val_acc: 0.3807\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.5480 - acc: 0.4638 - val_loss: 1.7636 - val_acc: 0.3823\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.5196 - acc: 0.4763 - val_loss: 1.7445 - val_acc: 0.3993\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.4974 - acc: 0.4794 - val_loss: 1.7470 - val_acc: 0.3941\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.4738 - acc: 0.4906 - val_loss: 1.7436 - val_acc: 0.3952\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.4515 - acc: 0.4953 - val_loss: 1.7317 - val_acc: 0.4021\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 6s 113us/step - loss: 1.4262 - acc: 0.5041 - val_loss: 1.7375 - val_acc: 0.3994\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 6s 110us/step - loss: 1.4018 - acc: 0.5140 - val_loss: 1.7346 - val_acc: 0.4072\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 6s 111us/step - loss: 1.3834 - acc: 0.5197 - val_loss: 1.7142 - val_acc: 0.4080\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 6s 114us/step - loss: 1.3611 - acc: 0.5273 - val_loss: 1.7210 - val_acc: 0.4030\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 6s 112us/step - loss: 1.3445 - acc: 0.5311 - val_loss: 1.7207 - val_acc: 0.4048\n",
            "Experiment with batch_size = 256\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer0 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "hidden_layer6 (Dense)        (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,752,754\n",
            "Trainable params: 1,750,722\n",
            "Non-trainable params: 2,032\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 5s 91us/step - loss: 2.3585 - acc: 0.1432 - val_loss: 2.2831 - val_acc: 0.1758\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 2.2161 - acc: 0.1852 - val_loss: 2.1907 - val_acc: 0.1976\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 2.1546 - acc: 0.2137 - val_loss: 2.1499 - val_acc: 0.2145\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 2.1153 - acc: 0.2284 - val_loss: 2.1232 - val_acc: 0.2281\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 3s 62us/step - loss: 2.0832 - acc: 0.2446 - val_loss: 2.1042 - val_acc: 0.2379\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 3s 63us/step - loss: 2.0577 - acc: 0.2580 - val_loss: 2.0853 - val_acc: 0.2469\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 2.0341 - acc: 0.2691 - val_loss: 2.0680 - val_acc: 0.2542\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 2.0116 - acc: 0.2795 - val_loss: 2.0564 - val_acc: 0.2618\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.9913 - acc: 0.2908 - val_loss: 2.0413 - val_acc: 0.2728\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 1.9716 - acc: 0.2991 - val_loss: 2.0272 - val_acc: 0.2761\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 1.9531 - acc: 0.3085 - val_loss: 2.0159 - val_acc: 0.2811\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 1.9357 - acc: 0.3137 - val_loss: 2.0072 - val_acc: 0.2851\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 3s 63us/step - loss: 1.9178 - acc: 0.3220 - val_loss: 1.9958 - val_acc: 0.2930\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.9009 - acc: 0.3297 - val_loss: 1.9868 - val_acc: 0.2939\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.8837 - acc: 0.3380 - val_loss: 1.9776 - val_acc: 0.3000\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 1.8669 - acc: 0.3426 - val_loss: 1.9666 - val_acc: 0.3002\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.8499 - acc: 0.3473 - val_loss: 1.9581 - val_acc: 0.3048\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.8343 - acc: 0.3550 - val_loss: 1.9482 - val_acc: 0.3115\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.8170 - acc: 0.3637 - val_loss: 1.9408 - val_acc: 0.3100\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.8005 - acc: 0.3684 - val_loss: 1.9335 - val_acc: 0.3159\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 3s 63us/step - loss: 1.7858 - acc: 0.3731 - val_loss: 1.9262 - val_acc: 0.3139\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.7689 - acc: 0.3790 - val_loss: 1.9190 - val_acc: 0.3190\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 3s 63us/step - loss: 1.7525 - acc: 0.3883 - val_loss: 1.9107 - val_acc: 0.3223\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.7371 - acc: 0.3916 - val_loss: 1.9047 - val_acc: 0.3272\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.7207 - acc: 0.3978 - val_loss: 1.8996 - val_acc: 0.3341\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.7041 - acc: 0.4043 - val_loss: 1.8939 - val_acc: 0.3297\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.6886 - acc: 0.4102 - val_loss: 1.8877 - val_acc: 0.3291\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 1.6714 - acc: 0.4162 - val_loss: 1.8824 - val_acc: 0.3346\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 3s 65us/step - loss: 1.6558 - acc: 0.4220 - val_loss: 1.8795 - val_acc: 0.3372\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 1.6394 - acc: 0.4310 - val_loss: 1.8701 - val_acc: 0.3400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQLZF4QR20zd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "072b7437-14ce-41cc-c6cc-7ad27b5bf875"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH4o7KfjxzLaRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}